{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDA and Normalization1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Upload Data Set"
      ],
      "metadata": {
        "id": "urirhsO6Datw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0RQv8ScB9dI",
        "outputId": "1077ee81-1dca-4283-b155-25a9ecc3bddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "Ah2UP2y-CLP_",
        "outputId": "fcae5bba-0615-4766-e2bc-8c2045aa8676",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "e6Ng_iDtDk5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "zo0mowbrDnJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d datatattle/covid-19-nlp-text-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBbEh6CwDpAG",
        "outputId": "63813d82-74ba-4d36-9c7c-faabaf3bdd96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading covid-19-nlp-text-classification.zip to /content\n",
            "\r  0% 0.00/4.38M [00:00<?, ?B/s]\n",
            "\r100% 4.38M/4.38M [00:00<00:00, 71.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \\*.zip && rm *.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvprDS2REBqV",
        "outputId": "bf0e6081-eb8e-49dd-be4f-f971a2d43099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  covid-19-nlp-text-classification.zip\n",
            "replace Corona_NLP_test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adding Required Libraries"
      ],
      "metadata": {
        "id": "vh5A4gUyFaM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "XmedKQXrEt-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Understanding Data"
      ],
      "metadata": {
        "id": "u58piZZ-GV6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"Corona_NLP_train.csv\",encoding='ISO-8859-1')\n",
        "test = pd.read_csv(\"Corona_NLP_test.csv\",encoding='ISO-8859-1')"
      ],
      "metadata": {
        "id": "35vOD2mZFhcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "Oo77dcVsGQ1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "XhFSYGe7GmNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.info()"
      ],
      "metadata": {
        "id": "vq-m8e-xGwK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum(axis = 0)"
      ],
      "metadata": {
        "id": "NUxIkWZWG001"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.isnull().sum(axis = 0)"
      ],
      "metadata": {
        "id": "kwz3xzFQG_3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"Sentiment\"].value_counts()"
      ],
      "metadata": {
        "id": "y6tmTDqGHD19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[\"Sentiment\"].value_counts()"
      ],
      "metadata": {
        "id": "BOim0eW3HPJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=make_subplots(1,2,subplot_titles=('Train set','Test set'))\n",
        "x=train[\"Sentiment\"].value_counts()\n",
        "fig.add_trace(go.Bar(x=x.index,y=x.values,marker_color= [\"forestgreen\",\"lightgreen\",\"lightseagreen\",\"red\",\"darkred\"],name='train'),row=1,col=1)\n",
        "x=test[\"Sentiment\"].value_counts()\n",
        "fig.add_trace(go.Bar(x=x.index,y=x.values,marker_color=[\"forestgreen\",\"lightgreen\",\"lightseagreen\",\"red\",\"darkred\"],name='test'),row=1,col=2)"
      ],
      "metadata": {
        "id": "YcOP4qJ9H-sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_3s = train.copy()\n",
        "test_3s = test.copy()"
      ],
      "metadata": {
        "id": "qwlT6uUcR1Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "five2three = {\"Extremely Positive\":\"Positive\",\"Positive\":\"Positive\",\"Neutral\":\"Neutral\",\"Negative\":\"Negative\",\"Extremely Negative\":\"Negative\"}\n",
        "train_3s[\"Sentiment\"] = [five2three[x] for x in train_3s[\"Sentiment\"]]\n",
        "test_3s[\"Sentiment\"] = [five2three[x] for x in test_3s[\"Sentiment\"]]"
      ],
      "metadata": {
        "id": "PAtnq9ReHXXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_3s[\"Sentiment\"].value_counts()"
      ],
      "metadata": {
        "id": "AqJyLjotSJod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=make_subplots(1,2,subplot_titles=('Train set','Test set'))\n",
        "x=train_3s[\"Sentiment\"].value_counts()\n",
        "fig.add_trace(go.Bar(x=x.index,y=x.values,marker_color= [\"forestgreen\",\"lightseagreen\",\"red\"],name='train'),row=1,col=1)\n",
        "x=test_3s[\"Sentiment\"].value_counts()\n",
        "fig.add_trace(go.Bar(x=x.index,y=x.values,marker_color=[\"forestgreen\",\"lightseagreen\",\"red\"],name='test'),row=1,col=2)"
      ],
      "metadata": {
        "id": "998IMkLMSXfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = train_3s[\"Sentiment\"].value_counts()\n",
        "mylabels = [\"Positive\", \"Negative\", \"Netural\"]\n",
        "explode = (0.1, 0, 0)\n",
        "plt.pie(y, labels = mylabels,explode= explode, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "plt.title(\"Train Set 3 Sentiment\")\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "2rMUTzEGHY64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = test_3s[\"Sentiment\"].value_counts()\n",
        "mylabels = [\"Negative\", \"Positive\", \"Netural\"]\n",
        "explode = (0.1, 0, 0)\n",
        "plt.pie(y, labels = mylabels,explode= explode, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "plt.title(\"Test Set 3 Sentiment\")\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "HCPYlcicKG3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = train[\"Sentiment\"].value_counts()\n",
        "mylabels = [\"Positive\", \"Negative\", \"Netural\",\"Extremely Positive\",\"Extremely Negative\"]\n",
        "explode = (0.1, 0, 0,0,0)\n",
        "plt.pie(y, labels = mylabels,explode= explode, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "plt.title(\"Train Set 5 Sentiment\")\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "KRO9qrZ7KpZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = train[\"Sentiment\"].value_counts()\n",
        "mylabels = [\"Negative\",\"Positive\",  \"Netural\",\"Extremely Positive\",\"Extremely Negative\"]\n",
        "explode = (0.1, 0, 0,0,0)\n",
        "plt.pie(y, labels = mylabels,explode= explode, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "plt.title(\"Test Set 5 Sentiment\")\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "H5wBThxzK_vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train['OriginalTweet'].values\n",
        "y = train['Sentiment'].values"
      ],
      "metadata": {
        "id": "J-J06-ifUi66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "xvQuDX2YUlfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = [len(X_train),len(X_valid),len(test)]\n",
        "mylabels = [\"Train\",\"Validation\",  \"Test\"]\n",
        "explode = (0.1, 0.1, 0.1)\n",
        "plt.pie(values, labels = mylabels,explode= explode, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "plt.title(\"Train-Validation-Test Split\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8SRZKjvcUv_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([train,test])"
      ],
      "metadata": {
        "id": "b6d2XtYqWaZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
      ],
      "metadata": {
        "id": "6ox8Z7gUfPpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[30, 15])\n",
        "\n",
        "df_pos = df[df[\"Sentiment\"]==\"positive\"]\n",
        "df_neg = df[df[\"Sentiment\"]==\"negative\"]\n",
        "df_neu = df[df[\"Sentiment\"]==\"neutral\"]\n",
        "\n",
        "comment_words = '' \n",
        "stopwords = set(STOPWORDS) \n",
        "\n",
        "for val in df_pos.text: \n",
        "      \n",
        "    # typecaste each val to string \n",
        "    val = str(val) \n",
        "  \n",
        "    # split the value \n",
        "    tokens = val.split() \n",
        "      \n",
        "    # Converts each token into lowercase \n",
        "    for i in range(len(tokens)): \n",
        "        tokens[i] = tokens[i].lower() \n",
        "      \n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        "   \n",
        "\n",
        "wordcloud1 = WordCloud(width = 800, height = 800, \n",
        "                background_color ='white',\n",
        "                colormap=\"Greens\",\n",
        "                stopwords = stopwords, \n",
        "                min_font_size = 10).generate(comment_words) \n",
        "\n",
        "ax1.imshow(wordcloud1)\n",
        "ax1.axis('off')\n",
        "ax1.set_title('Positive Sentiment',fontsize=35);\n",
        "\n",
        "comment_words = ''\n",
        "\n",
        "for val in df_neg.text: \n",
        "      \n",
        "    # typecaste each val to string \n",
        "    val = str(val) \n",
        "  \n",
        "    # split the value \n",
        "    tokens = val.split() \n",
        "      \n",
        "    # Converts each token into lowercase \n",
        "    for i in range(len(tokens)): \n",
        "        tokens[i] = tokens[i].lower() \n",
        "      \n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "wordcloud2 = WordCloud(width = 800, height = 800, \n",
        "                background_color ='white',\n",
        "                colormap=\"Reds\",\n",
        "                stopwords = stopwords, \n",
        "                min_font_size = 10).generate(comment_words)  \n",
        "ax2.imshow(wordcloud2)\n",
        "ax2.axis('off')\n",
        "ax2.set_title('Negative Sentiment',fontsize=35);\n",
        "\n",
        "\n",
        "\n",
        "comment_words = ''\n",
        "for val in df_neu.text: \n",
        "      \n",
        "    # typecaste each val to string \n",
        "    val = str(val) \n",
        "  \n",
        "    # split the value \n",
        "    tokens = val.split() \n",
        "      \n",
        "    # Converts each token into lowercase \n",
        "    for i in range(len(tokens)): \n",
        "        tokens[i] = tokens[i].lower() \n",
        "      \n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "wordcloud3 = WordCloud(width = 800, height = 800, \n",
        "                background_color ='white',\n",
        "                colormap=\"Greys\",\n",
        "                stopwords = stopwords, \n",
        "                min_font_size = 10).generate(comment_words) \n",
        "ax3.imshow(wordcloud3)\n",
        "ax3.axis('off')\n",
        "ax3.set_title('Neutal Sentiment',fontsize=35);"
      ],
      "metadata": {
        "id": "vHXNLvJZbJtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cleaning & Normalization 1"
      ],
      "metadata": {
        "id": "44_QxBJNTK9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Deleting Duplicate Tweets\n",
        "*   Deleting Unnecessary Columns\n",
        "*   3 and 5 Sentiment Datasets\n"
      ],
      "metadata": {
        "id": "uzFtw2V-TRZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy of train and test data"
      ],
      "metadata": {
        "id": "_1bUwZzrWtHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_n1 = train.copy()\n",
        "test_n1 = test.copy()"
      ],
      "metadata": {
        "id": "gerQBNbMVZ3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deleting Duplicate Tweets"
      ],
      "metadata": {
        "id": "4kSQgs3VW372"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_n1.drop_duplicates(subset=\"OriginalTweet\",inplace=True)\n",
        "test_n1.drop_duplicates(subset=\"OriginalTweet\",inplace=True)"
      ],
      "metadata": {
        "id": "tjO2tBqZTIjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deleting Unnecessary Columns\n"
      ],
      "metadata": {
        "id": "uvItTcR3W9Mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_n1 = train_n1[[\"OriginalTweet\",\"Sentiment\"]]\n",
        "test_n1 = test_n1[[\"OriginalTweet\",\"Sentiment\"]]"
      ],
      "metadata": {
        "id": "UJLBtjjyUyUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_n1.info()"
      ],
      "metadata": {
        "id": "V4v4OZ9oU4j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_n1.info()"
      ],
      "metadata": {
        "id": "uC6vEMRlV-du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating 3 Sentiment Dataset"
      ],
      "metadata": {
        "id": "NmM5ZOm3XCu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_n1_3s = train_n1.copy()\n",
        "test_n1_3s = test_n1.copy()"
      ],
      "metadata": {
        "id": "XvnYEhZIWA3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "five2three = {\"Extremely Positive\":\"Positive\",\"Positive\":\"Positive\",\"Neutral\":\"Neutral\",\"Negative\":\"Negative\",\"Extremely Negative\":\"Negative\"}\n",
        "train_n1_3s[\"Sentiment\"] = [five2three[x] for x in train_n1_3s[\"Sentiment\"]]\n",
        "test_n1_3s[\"Sentiment\"] = [five2three[x] for x in test_n1_3s[\"Sentiment\"]]"
      ],
      "metadata": {
        "id": "3af-LgI1WL01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_n1_3s[\"Sentiment\"].value_counts()"
      ],
      "metadata": {
        "id": "v6Ea0ip-WXbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save New Datasets"
      ],
      "metadata": {
        "id": "LwQbDJwOXK4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_n1.to_csv(\"COVID19_train_N1_S5.csv\", index = False)\n",
        "test_n1.to_csv(\"COVID19_test_N1_S5.csv\", index = False)\n",
        "test_n1_3s.to_csv(\"COVID19_test_N1_S3.csv\", index = False)\n",
        "train_n1_3s.to_csv(\"COVID19_train_N1_S3.csv\",index = False)"
      ],
      "metadata": {
        "id": "48geY6WyWdR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_n1_3s.isnull().sum(axis = 0)"
      ],
      "metadata": {
        "id": "bCc1qHlnVqzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tXcLMzeSVut-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}